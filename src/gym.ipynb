{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: pandas in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: PyQt6 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (6.8.1)\n",
      "Requirement already satisfied: gymnasium in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: PyQt6-sip<14,>=13.8 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from PyQt6) (13.10.0)\n",
      "Requirement already satisfied: PyQt6-Qt6<6.9.0,>=6.8.0 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from PyQt6) (6.8.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from gymnasium) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from gymnasium) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: moviepy>=1.0.0 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from gymnasium[other]) (2.1.2)\n",
      "Requirement already satisfied: matplotlib>=3.0 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from gymnasium[other]) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=3.0 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from gymnasium[other]) (4.11.0.86)\n",
      "Requirement already satisfied: seaborn>=0.13 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from gymnasium[other]) (0.13.2)\n",
      "Requirement already satisfied: pygame>=2.1.3 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from gymnasium[classic-control]) (2.6.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[other]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[other]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[other]) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[other]) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[other]) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[other]) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from matplotlib>=3.0->gymnasium[other]) (3.2.1)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from moviepy>=1.0.0->gymnasium[other]) (5.1.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from moviepy>=1.0.0->gymnasium[other]) (2.37.0)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from moviepy>=1.0.0->gymnasium[other]) (0.6.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from moviepy>=1.0.0->gymnasium[other]) (0.1.10)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from moviepy>=1.0.0->gymnasium[other]) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: tqdm in /home/kasper/Documents/Civilingenioer_Robotteknologi/Bachelor/.venv/lib/python3.10/site-packages (from proglog<=1.0.0->moviepy>=1.0.0->gymnasium[other]) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy pandas PyQt6 gymnasium \"gymnasium[other]\" \"gymnasium[classic-control]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### World class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldEnv(gym.Env):\n",
    "\n",
    "    def __init__(self, size: int = 10):\n",
    "        # The size of the square grid\n",
    "        self.size = size\n",
    "        self.trajectory = []\n",
    "        self.world = np.zeros((size, size))\n",
    "\n",
    "        # Define the agent and target location; randomly chosen in `reset` and updated in `step`\n",
    "        self._agent_location = np.array([-1, -1], dtype=np.int32)\n",
    "        self._target_location = np.array([-1, -1], dtype=np.int32)\n",
    "\n",
    "        # Observations are dictionaries with the agent's and the target's location.\n",
    "        # Each location is encoded as an element of {0, ..., `size`-1}^2\n",
    "        self.observation_space = gym.spaces.Dict(\n",
    "            {\n",
    "                \"agent\": gym.spaces.Box(0, size - 1, shape=(2,), dtype=int),\n",
    "                \"target\": gym.spaces.Box(0, size - 1, shape=(2,), dtype=int),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # We have 4 actions, corresponding to \"right\", \"up\", \"left\", \"down\"\n",
    "        self.action_space = gym.spaces.Discrete(8)\n",
    "        # Dictionary maps the abstract actions to the directions on the grid\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([1, 0]),  # right\n",
    "            1: np.array([0, 1]),  # up\n",
    "            2: np.array([-1, 0]),  # left\n",
    "            3: np.array([0, -1]),  # down\n",
    "            4: np.array([1, 1]),  # up-right\n",
    "            5: np.array([-1, 1]),  # up-left\n",
    "            6: np.array([-1, -1]),  # down-left\n",
    "            7: np.array([1, -1]),  # down-right\n",
    "        }\n",
    "    \n",
    "    def _get_info(self):\n",
    "        return {\n",
    "            \"distance\": np.linalg.norm(\n",
    "                self._agent_location - self._target_location, ord=1\n",
    "            )\n",
    "        }\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return {\"agent\": self._agent_location, \"target\": self._target_location}\n",
    "\n",
    "    def reset(self, seed: Optional[int] = None, options: Optional[dict] = None):\n",
    "        # We need the following line to seed self.np_random\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # Choose the agent's location uniformly at random\n",
    "        self._agent_location = self.np_random.integers(0, self.size, size=2, dtype=int)\n",
    "\n",
    "        # We will sample the target's location randomly until it does not coincide with the agent's location\n",
    "        self._target_location = self._agent_location\n",
    "        while np.array_equal(self._target_location, self._agent_location):\n",
    "            self._target_location = self.np_random.integers(\n",
    "                0, self.size, size=2, dtype=int\n",
    "            )\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "    def getReward(self):\n",
    "        return self.world[self._agent_location[0], self._agent_location[1]]\n",
    "\n",
    "        \n",
    "\n",
    "    def step(self, action):\n",
    "        # Map the action (element of {0,1,2,3,4,5,6,7}) to the direction we walk in\n",
    "        direction = self._action_to_direction[action]\n",
    "        # We use `np.clip` to make sure we don't leave the grid bounds\n",
    "        self._agent_location = np.clip(\n",
    "            self._agent_location + direction, 0, self.size - 1\n",
    "        )\n",
    "\n",
    "        # An environment is completed if and only if the agent has searched all states\n",
    "        terminated = np.array_equal(self._agent_location, self._target_location)\n",
    "        truncated = False\n",
    "        reward = self.getReward()\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation, reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAR_agent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: gym.Env,\n",
    "        learning_rate: float,\n",
    "        initial_epsilon: float,\n",
    "        epsilon_decay: float,\n",
    "        final_epsilon: float,\n",
    "        discount_factor: float = 0.95,\n",
    "    ):\n",
    "        \"\"\"Initialize a Reinforcement Learning agent with an empty dictionary\n",
    "        of state-action values (q_values), a learning rate and an epsilon.\n",
    "\n",
    "        Args:\n",
    "            env: The training environment\n",
    "            learning_rate: The learning rate\n",
    "            initial_epsilon: The initial epsilon value\n",
    "            epsilon_decay: The decay for epsilon\n",
    "            final_epsilon: The final epsilon value\n",
    "            discount_factor: The discount factor for computing the Q-value\n",
    "        \"\"\"\n",
    "        self.env = env\n",
    "        self.q_values = defaultdict(lambda: np.zeros(env.action_space.n))   # Q-values for each state-action pair\n",
    "\n",
    "        self.lr = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "\n",
    "        self.epsilon = initial_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.final_epsilon = final_epsilon\n",
    "        self.beta = 0.85\n",
    "\n",
    "        self.training_error = []\n",
    "\n",
    "    def softmax_function(self):\n",
    "        \"\"\"\"Softmax function to compute the probabilities of each action.\"\"\"\n",
    "        # We take an action based on the softmax function.\n",
    "        # The softmax function is defined as the probability of taking an action.\n",
    "        # We take the action with the highest probability.\n",
    "        exp_q = np.exp(self.beta * self.q_values)  # Apply temperature scaling\n",
    "        probabilities = exp_q / np.sum(exp_q)  # Normalize to create probability distribution\n",
    "        return probabilities\n",
    "\n",
    "    # def get_action(self):\n",
    "    #     \"\"\"Select an action based on the computed softmax probabilities.\"\"\"\n",
    "    #     probabilities = self.softmax_function()\n",
    "    #     action = np.random.choice(len(self.q_values), p=probabilities)  # Takes a action based on the probabilites from the softmax policy\n",
    "    #     return action\n",
    "\n",
    "    def get_action(self, obs: dict) -> int:\n",
    "        \"\"\"\n",
    "        Returns the best action with probability (1 - epsilon)\n",
    "        otherwise a random action with probability epsilon to ensure exploration.\n",
    "        \"\"\"\n",
    "        # Convert agent's position to a tuple so it can be used as a dictionary key\n",
    "        agent_state = tuple(obs['agent'])  \n",
    "\n",
    "        # Ensure the state exists in the Q-table\n",
    "        if agent_state not in self.q_values:\n",
    "            self.q_values[agent_state] = np.zeros(self.env.action_space.n)\n",
    "\n",
    "        # Exploration: With probability epsilon, take a random action\n",
    "        if np.random.random() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "\n",
    "        # Exploitation: Take the best known action\n",
    "        return int(np.argmax(self.q_values[agent_state]))\n",
    "\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        obs: dict,  # Changed to dict\n",
    "        action: int,\n",
    "        reward: float,\n",
    "        terminated: bool,\n",
    "        next_obs: dict,  # Changed to dict\n",
    "    ):\n",
    "        \"\"\"Updates the Q-value of an action using Q-learning.\"\"\"\n",
    "        \n",
    "        # Extract agent's position and convert to tuple (ensuring it's hashable)\n",
    "        agent_state = tuple(obs['agent'])  \n",
    "        next_agent_state = tuple(next_obs['agent'])  \n",
    "\n",
    "        # Ensure both states exist in Q-table\n",
    "        if agent_state not in self.q_values:\n",
    "            self.q_values[agent_state] = np.zeros(self.env.action_space.n)\n",
    "        if next_agent_state not in self.q_values:\n",
    "            self.q_values[next_agent_state] = np.zeros(self.env.action_space.n)\n",
    "\n",
    "        # Compute future Q-value\n",
    "        future_q_value = (not terminated) * np.max(self.q_values[next_agent_state])\n",
    "\n",
    "        # Compute temporal difference (TD) error\n",
    "        temporal_difference = (\n",
    "            reward + self.discount_factor * future_q_value - self.q_values[agent_state][action]\n",
    "        )\n",
    "\n",
    "        # Update Q-value\n",
    "        self.q_values[agent_state][action] += self.lr * temporal_difference\n",
    "\n",
    "        # Track training error\n",
    "        self.training_error.append(temporal_difference)\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "            self.epsilon = max(self.final_epsilon, self.epsilon - self.epsilon_decay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "learning_rate = 0.01\n",
    "n_episodes = 100_00\n",
    "start_epsilon = 1.0\n",
    "epsilon_decay = start_epsilon / (n_episodes / 2)  # reduce the exploration over time\n",
    "final_epsilon = 0.1\n",
    "\n",
    "env = GridWorldEnv(size=10)\n",
    "env = gym.wrappers.TimeLimit(env, max_episode_steps=100)\n",
    "\n",
    "agent = SAR_agent(\n",
    "    env=env,\n",
    "    learning_rate=learning_rate,\n",
    "    initial_epsilon=start_epsilon,\n",
    "    epsilon_decay=epsilon_decay,\n",
    "    final_epsilon=final_epsilon,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:12<00:00, 774.57it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for episode in tqdm(range(n_episodes)):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "\n",
    "    # play one episode\n",
    "    while not done:\n",
    "        action = agent.get_action(obs)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        # update the agent\n",
    "        agent.update(obs, action, reward, terminated, next_obs)\n",
    "\n",
    "        # update if the environment is done and the current obs\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "\n",
    "    agent.decay_epsilon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TimeLimit' object has no attribute 'return_queue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m     12\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode rewards\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m reward_moving_average \u001b[38;5;241m=\u001b[39m get_moving_avgs(\n\u001b[0;32m---> 14\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_queue\u001b[49m,\n\u001b[1;32m     15\u001b[0m     rolling_length,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(reward_moving_average)), reward_moving_average)\n\u001b[1;32m     20\u001b[0m axs[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode lengths\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TimeLimit' object has no attribute 'return_queue'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_moving_avgs(arr, window, convolution_mode):\n",
    "    return np.convolve(\n",
    "        np.array(arr).flatten(),\n",
    "        np.ones(window),\n",
    "        mode=convolution_mode\n",
    "    ) / window\n",
    "\n",
    "# Smooth over a 500 episode window\n",
    "rolling_length = 500\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(12, 5))\n",
    "\n",
    "axs[0].set_title(\"Episode rewards\")\n",
    "reward_moving_average = get_moving_avgs(\n",
    "    env.return_queue,\n",
    "    rolling_length,\n",
    "    \"valid\"\n",
    ")\n",
    "axs[0].plot(range(len(reward_moving_average)), reward_moving_average)\n",
    "\n",
    "axs[1].set_title(\"Episode lengths\")\n",
    "length_moving_average = get_moving_avgs(\n",
    "    env.length_queue,\n",
    "    rolling_length,\n",
    "    \"valid\"\n",
    ")\n",
    "axs[1].plot(range(len(length_moving_average)), length_moving_average)\n",
    "\n",
    "axs[2].set_title(\"Training Error\")\n",
    "training_error_moving_average = get_moving_avgs(\n",
    "    agent.training_error,\n",
    "    rolling_length,\n",
    "    \"same\"\n",
    ")\n",
    "axs[2].plot(range(len(training_error_moving_average)), training_error_moving_average)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record Agent\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gymnasium as gym\n",
    "# from gymnasium.wrappers import RecordEpisodeStatistics, RecordVideo\n",
    "\n",
    "# num_eval_episodes = 4\n",
    "\n",
    "# env = GridWorldEnv(size=10)\n",
    "# env = RecordVideo(env, video_folder=\"cartpole-agent\", name_prefix=\"eval\",\n",
    "#                   episode_trigger=lambda x: True)\n",
    "# env = RecordEpisodeStatistics(env, buffer_length=num_eval_episodes)\n",
    "\n",
    "# for episode_num in range(num_eval_episodes):\n",
    "#     obs, info = env.reset()\n",
    "\n",
    "#     episode_over = False\n",
    "#     while not episode_over:\n",
    "#         action = env.action_space.sample()  # replace with actual agent\n",
    "#         obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "#         episode_over = terminated or truncated\n",
    "# env.close()\n",
    "\n",
    "# print(f'Episode time taken: {env.time_queue}')\n",
    "# print(f'Episode total rewards: {env.return_queue}')\n",
    "# print(f'Episode lengths: {env.length_queue}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
